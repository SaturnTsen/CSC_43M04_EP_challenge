import warnings
warnings.filterwarnings("ignore", message="xFormers is available")

import torch
import wandb
import hydra
import os
from pathlib import Path

from tqdm import tqdm
from torch import nn
from torch.optim import Optimizer
from torch.utils.data import DataLoader
from hydra.core.config_store import ConfigStore
from omegaconf import OmegaConf

from data.datamodule import DataModule, BatchDict
from configs.experiments.base import BaseTrainConfig
from utils.sanity import show_images, check_initial_loss
from utils.validation import validate_and_log  # ÂØºÂÖ•È™åËØÅÂáΩÊï∞
from utils.transforms import TargetStandardizer  # ÂØºÂÖ•Ê†áÂáÜÂåñÂ∑•ÂÖ∑

@hydra.main(config_path="configs", config_name=None, version_base="1.3")
def train(cfg: BaseTrainConfig) -> None:
    logger = (
        wandb.init(project="challenge_CSC_43M04_EP", name=cfg.experiment_name)
        if cfg.log
        else None
    )
    
    device : torch.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model : nn.Module = hydra.utils.instantiate(cfg.model.instance).to(device)
    
    optimizer : Optimizer = hydra.utils.instantiate(cfg.optim, params=model.parameters())
    loss_fn : nn.Module = hydra.utils.instantiate(cfg.loss_fn)
    
    datamodule : DataModule = hydra.utils.instantiate(cfg.datamodule)
    train_loader : DataLoader = datamodule.train_dataloader()
    val_loader : DataLoader = datamodule.val_dataloader()
    
    # Á°ÆÂÆöÊòØÂê¶‰ΩøÁî®Ê†áÂáÜÂåñ
    target_standardizer = None
    if hasattr(cfg.datamodule, 'standardize_target') and cfg.datamodule.standardize_target:
        target_standardizer = TargetStandardizer(
            mu=cfg.datamodule.target_mu,
            sigma=cfg.datamodule.target_sigma
        )
        print(f"Use target standardization: mu={cfg.datamodule.target_mu}, sigma={cfg.datamodule.target_sigma}")
    
    train_sanity : wandb.Image = show_images(train_loader, name="assets/sanity/train_images")
    (
        logger.log({"sanity_checks/train_images": wandb.Image(train_sanity)})
        if logger is not None
        else None
    )
    if val_loader is not None:
        val_sanity = show_images(val_loader, name="assets/sanity/val_images")
        logger.log(
            {"sanity_checks/val_images": wandb.Image(val_sanity)}
        ) if logger is not None else None

    # ÂàõÂª∫ËæìÂá∫ÁõÆÂΩï - ‰ΩøÁî®HydraÁöÑÂ∑•‰ΩúÁõÆÂΩï
    save_dir = cfg.msle_validation_dir
    os.makedirs(save_dir, exist_ok=True)
    print(f"MSLE validation results will be saved to: {save_dir}")

    # Ëé∑ÂèñmsleÈ™åËØÅÈ¢ëÁéá
    msle_validation_interval = cfg.msle_validation_interval
    
    # üîç Ê£ÄÊü•ÂàùÂßãÊçüÂ§±ÔºàËÆ≠ÁªÉÂâçÔºâ
    print("\n" + "="*60)
    print("üîç ËÆ≠ÁªÉÂâçÂàùÂßãÊçüÂ§±Ê£ÄÊü•")
    print("="*60)
    
    initial_train_loss = check_initial_loss(
        model=model, 
        data_loader=train_loader, 
        loss_fn=loss_fn, 
        device=device, 
        name="ËÆ≠ÁªÉÈõÜ"
    )
    
    if val_loader is not None and len(val_loader) > 0:
        initial_val_loss = check_initial_loss(
            model=model, 
            data_loader=val_loader, 
            loss_fn=loss_fn, 
            device=device, 
            name="È™åËØÅÈõÜ"
        )
    else:
        initial_val_loss = float('inf')
        print("‚ö†Ô∏è  È™åËØÅÈõÜ‰∏∫Á©∫ÔºåË∑≥ËøáÈ™åËØÅÈõÜÂàùÂßãÊçüÂ§±Ê£ÄÊü•")
    
    # ËÆ∞ÂΩïÂàùÂßãÊçüÂ§±Âà∞wandb
    if logger is not None:
        logger.log({
            "initial_loss/train": initial_train_loss,
            "initial_loss/val": initial_val_loss,
        })
    
    print(f"\nüìä ÂàùÂßãÊçüÂ§±ÊÄªÁªì:")
    print(f"  ËÆ≠ÁªÉÈõÜ: {initial_train_loss:.4f}")
    print(f"  È™åËØÅÈõÜ: {initial_val_loss:.4f}")
    print("="*60)
    
    # ËÆ∞ÂΩïËÆ≠ÁªÉÈÖçÁΩÆ
    if logger is not None:
        config_dict = OmegaConf.to_container(cfg, resolve=True)
        logger.config.update(config_dict)
        logger.log({
            "validation/msle_interval": msle_validation_interval,
            "validation/save_dir": save_dir
        })

    # -- loop over epochs
    for epoch in tqdm(range(cfg.epochs), desc="Epochs"):
        # -- loop over training batches
        model.train()
        epoch_train_loss = 0
        num_samples_train = 0
        pbar = tqdm(train_loader, desc=f"Epoch {epoch}", leave=False)
        for i, batch in enumerate(pbar):
            batch: BatchDict = batch
            batch["image"] = batch["image"].to(device)
            # text Â≠óÊÆµ‰Ωú‰∏∫Â≠óÁ¨¶‰∏≤ÂàóË°®‰øùÊåÅÂú® CPU ‰∏äÔºåÊ®°Âûã‰ºöÂú®ÂÜÖÈÉ®ËøõË°å tokenization
            batch["target"] = batch["target"].to(device).squeeze()
            
            # Â¶ÇÊûúbatch‰∏≠Êúâage_yearÁâπÂæÅÔºå‰πüÁßªÂä®Âà∞ËÆæÂ§á‰∏ä
            if "age_year" in batch:
                batch["age_year"] = batch["age_year"].to(device)
                
            preds = model(batch).squeeze()
            loss = loss_fn(preds, batch["target"])
            (
                logger.log({"loss": loss.detach().cpu().numpy()})
                if logger is not None
                else None
            )
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            # Â¶ÇÊûúÊçüÂ§±ÂáΩÊï∞ÊîØÊåÅlambda schedulerÔºåÂàôÊõ¥Êñ∞lambdaÂÄº
            if hasattr(loss_fn, 'step'):
                current_lambda = loss_fn.step()
                if logger is not None and hasattr(loss_fn, 'get_current_lambda'):
                    logger.log({"train/current_lambda": loss_fn.get_current_lambda()})
            
            # ËÆ∞ÂΩïËûçÂêàÊùÉÈáçÔºàÂ¶ÇÊûúÊ®°ÂûãÊîØÊåÅÔºâ
            if hasattr(model, 'get_fusion_weights') and logger is not None:
                fusion_weights = model.get_fusion_weights()
                # ËÆ∞ÂΩïÊâÄÊúâËûçÂêàÊùÉÈáç
                for weight_name, weight_value in fusion_weights.items():
                    logger.log({f"train/{weight_name}": weight_value})
            elif hasattr(model, 'get_fusion_weight') and logger is not None:
                # ÂêëÂêéÂÖºÂÆπÔºöÂØπ‰∫éÂè™Êúâ‰∏§Ê®°ÊÄÅÁöÑÊóßÊ®°Âûã
                logger.log({"train/fusion_weight": model.get_fusion_weight()})
            
            epoch_train_loss += loss.detach().cpu().numpy() * len(batch["image"])
            num_samples_train += len(batch["image"])
            pbar.set_postfix({"train/loss_step": loss.detach().cpu().numpy()})
        epoch_train_loss /= num_samples_train
        (
            logger.log(
                {
                    "epoch": epoch,
                    "train/loss_epoch": epoch_train_loss,
                }
            )
            if logger is not None
            else None
        )

        # -- validation loop
        val_metrics = {}
        epoch_val_loss = 0
        num_samples_val = 0
        model.eval()
        if val_loader is not None: 
            for _, batch in enumerate(val_loader):
                batch: BatchDict = batch
                batch["image"] = batch["image"].to(device)
                # text Â≠óÊÆµ‰Ωú‰∏∫Â≠óÁ¨¶‰∏≤ÂàóË°®‰øùÊåÅÂú® CPU ‰∏ä
                batch["target"] = batch["target"].to(device).squeeze()
                
                # Â¶ÇÊûúbatch‰∏≠Êúâage_yearÁâπÂæÅÔºå‰πüÁßªÂä®Âà∞ËÆæÂ§á‰∏ä
                if "age_year" in batch:
                    batch["age_year"] = batch["age_year"].to(device)
                    
                with torch.no_grad():
                    preds = model(batch).squeeze()
                loss = loss_fn(preds, batch["target"])
                epoch_val_loss += loss.detach().cpu().numpy() * len(batch["image"])
                num_samples_val += len(batch["image"])
            epoch_val_loss /= num_samples_val
            val_metrics["val/loss_epoch"] = epoch_val_loss
            (
                logger.log(
                    {
                        "epoch": epoch,
                        **val_metrics,
                    }
                )
                if logger is not None
                else None
            )
            
        # Ê†πÊçÆÈÖçÁΩÆÁöÑÈó¥ÈöîËøõË°åMSLEÈ™åËØÅ
        if msle_validation_interval > 0 and ((epoch + 1) % msle_validation_interval == 0 or epoch == cfg.epochs - 1):
            print(f"\nExecuting MSLE validation for epoch {epoch}...")
            # ËøêË°åÈ™åËØÅÂπ∂ËÆ∞ÂΩïMSLEÂíåÈ¢ÑÊµãÁªìÊûú
            msle, _ = validate_and_log(
                model=model,
                val_loader=val_loader,
                device=device,
                epoch=epoch,
                target_standardizer=target_standardizer,
                experiment_name=cfg.experiment_name,
                save_dir=save_dir,
                log_wandb=cfg.log,
                logger=logger
            )
            # Âú®wandb‰∏≠ËÆ∞ÂΩïMSLE (‰ΩøÁî®Áªü‰∏ÄÁöÑÂëΩÂêç)
            if logger is not None:
                logger.log({
                    "epoch": epoch,
                    "validation/msle": msle
                })

    print(
        f"""Epoch {epoch}: 
        Training metrics:
        - Train Loss: {epoch_train_loss:.4f},
        Validation metrics: 
        - Val Loss: {epoch_val_loss:.4f}"""
    )

    if cfg.log:
        logger.finish()

    torch.save(model.state_dict(), cfg.checkpoint_path)


if __name__ == "__main__":
    import importlib
    import sys
    
    # Get config-name from command line arguments
    config_name = None
    for arg in sys.argv:
        if arg.startswith("--config-name="):
            config_name = arg.split("=")[1]
            break
    
    if config_name is None:
        raise ValueError("Please use --config-name to specify the config name")
    
    # Dynamically import config class
    try:
        config_module = importlib.import_module(f"configs.experiments.{config_name}")
        config_class = getattr(config_module, f"{config_name.capitalize()}TrainConfig")
    except (ImportError, AttributeError) as e:
        raise ImportError(f"Cannot load config {config_name}: {str(e)}")
    
    # Register config
    cs = ConfigStore.instance()
    cs.store(name=config_name, node=config_class)
    
    train()
