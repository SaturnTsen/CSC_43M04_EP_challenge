{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集探索\n",
    "\n",
    "本笔记本用于探索数据集的结构和特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pprint\n",
    "from tqdm.notebook import tqdm\n",
    "from omegaconf import OmegaConf\n",
    "from data.dataset import Dataset\n",
    "from data.datamodule import DataModule\n",
    "import pandas as pd\n",
    "import hydra\n",
    "from hydra import compose, initialize\n",
    "\n",
    "from hydra.core.config_store import ConfigStore\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "\n",
    "def load_config(config):\n",
    "    cs = ConfigStore.instance()\n",
    "    cs.store(name=\"cfg\", node=config)\n",
    "    with initialize(config_path=\"configs\", version_base=\"1.3\"):\n",
    "        cfg = compose(config_name=\"cfg\", return_hydra_config=True)\n",
    "        HydraConfig.instance().set_config(cfg)  # 手动设置 HydraConfig\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.experiments.base import BaseTrainConfig\n",
    "cfg = load_config(BaseTrainConfig)\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_dataset = hydra.utils.instantiate(cfg.dataset)\n",
    "\n",
    "views = train_val_dataset.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设你已经定义好了 views 是一个一维 np.ndarray\n",
    "# 示例: views = np.random.randint(0, 1000000, size=10000)\n",
    "assert isinstance(views, np.ndarray), \"views must be a NumPy array\"\n",
    "assert views.ndim == 1, \"views must be a 1D array\"\n",
    "\n",
    "# 可视化\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(x=views, bins=50)\n",
    "plt.title('Views Distribution')\n",
    "plt.xlabel('Views')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.histplot(x=views, bins=50, log_scale=(True, False))\n",
    "plt.title('Views Distribution (Logarithmic X Scale)')\n",
    "plt.xlabel('Views (Log)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.histplot(x=np.log1p(views), bins=50)\n",
    "plt.title('log1p(Views) Distribution')\n",
    "plt.xlabel('log1p(Views)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.boxplot(y=np.log1p(views))\n",
    "plt.title('log1p(Views) Boxplot')\n",
    "plt.ylabel('log1p(Views)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 数值统计\n",
    "print(\"Views Statistics:\")\n",
    "print(f\"Min: {views.min():,.0f}\")\n",
    "print(f\"Max: {views.max():,.0f}\")\n",
    "print(f\"Average: {views.mean():,.0f}\")\n",
    "print(f\"Median: {np.median(views):,.0f}\")\n",
    "print(f\"Standard Deviation: {views.std():,.0f}\")\n",
    "\n",
    "log_views = np.log1p(views)\n",
    "print(\"\\nlog1p(Views) Statistics:\")\n",
    "print(f\"Min: {log_views.min():.2f}\")\n",
    "print(f\"Max: {log_views.max():.2f}\")\n",
    "print(f\"Average: {log_views.mean():.2f}\")\n",
    "print(f\"Median: {np.median(log_views):.2f}\")\n",
    "print(f\"Standard Deviation: {log_views.std():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline prediction - mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "baseline_value = np.expm1(log_views.mean())\n",
    "\n",
    "test_dataset = Dataset(\n",
    "    cfg.datamodule.dataset_path,\n",
    "    \"test\",\n",
    "    transforms=hydra.utils.instantiate(cfg.datamodule.test_transform),\n",
    "    metadata=cfg.datamodule.metadata,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=20,\n",
    ")\n",
    "\n",
    "# 构造 submission 记录\n",
    "records = []\n",
    "for batch in test_loader:\n",
    "    ids = batch[\"id\"]\n",
    "    for id_ in ids:\n",
    "        records.append({\n",
    "            \"ID\": id_.item(),\n",
    "            \"views\": baseline_value,\n",
    "        })\n",
    "\n",
    "# 写入 CSV\n",
    "submission = pd.DataFrame(records)\n",
    "submission.to_csv(f\"{cfg.root_dir}/submissions/mean_baseline.csv\", index=False)\n",
    "print(f\"Baseline submission saved to: {cfg.root_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_csv = r\"D:\\Personal\\Polytechnique\\2A\\DL_projet\\CSC_43M04_EP_challenge\\outputs\\2025-05-17\\17-00-56\\weighted_loss_experiment_epoch32_20250517-172946.csv\"\n",
    "df = pd.read_csv(val_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ===== 基础列计算 =====\n",
    "df['log_actual'] = np.log1p(df['actual_views'])\n",
    "df['log_pred'] = np.log1p(df['predicted_views'])\n",
    "df['log_error'] = df['log_pred'] - df['log_actual']\n",
    "df['msle_contribution'] = df['log_error'] ** 2\n",
    "\n",
    "# ===== 图1：Predicted vs Actual (log1p scale) =====\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(df['log_actual'], df['log_pred'], alpha=0.5)\n",
    "plt.plot([0, df['log_actual'].max()], [0, df['log_actual'].max()], 'r--')\n",
    "plt.xlabel('log1p(Actual Views)')\n",
    "plt.ylabel('log1p(Predicted Views)')\n",
    "plt.title('Predicted vs Actual (log1p scale)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('pred_vs_actual_log1p.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# ===== 图2：Log Residuals =====\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['log_actual'], df['log_error'], alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('log1p(Actual Views)')\n",
    "plt.ylabel('log Residual (log(pred+1) - log(actual+1))')\n",
    "plt.title('Log-space Residuals (Core to MSLE)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('log_residuals.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# ===== 图3：Log Residual Histogram =====\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(df['log_error'].clip(-5, 5), bins=50)\n",
    "plt.xlabel('Log Residual')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of log-space residuals')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('log_residual_hist.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# ===== 图4：Boxplot of Log Residuals by log1p Actual Bin =====\n",
    "df['log_bin'] = pd.cut(df['log_actual'], bins=10)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='log_bin', y='log_error', data=df)\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('log1p(Actual Views)')\n",
    "plt.ylabel('log Residual')\n",
    "plt.title('Log Residuals by log1p Actual View Count Bins')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('log_error_by_log_actual.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# ===== 图5：Top 15 MSLE Contributors =====\n",
    "top_msle = df.sort_values('msle_contribution', ascending=False).head(15)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='ID', y='msle_contribution', data=top_msle)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Video ID')\n",
    "plt.ylabel('MSLE Contribution')\n",
    "plt.title('Top 15 MSLE-Contributing Examples')\n",
    "plt.tight_layout()\n",
    "plt.savefig('top_msle_contributors.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# ===== 图6：MSLE Contribution Heatmap =====\n",
    "df['log_pred_bin'] = pd.cut(df['log_pred'], bins=10)\n",
    "df['log_actual_bin'] = pd.cut(df['log_actual'], bins=10)\n",
    "\n",
    "pivot = pd.pivot_table(df, values='msle_contribution',\n",
    "                       index='log_actual_bin',\n",
    "                       columns='log_pred_bin',\n",
    "                       aggfunc='mean', fill_value=0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(pivot, cmap='YlOrRd')\n",
    "plt.xlabel('log1p(Predicted Views)')\n",
    "plt.ylabel('log1p(Actual Views)')\n",
    "plt.title('MSLE Contribution Heatmap (Mean per Bin)')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('msle_heatmap_logbins.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置爆款门槛：100万次以上\n",
    "viral_threshold = int(np.expm1(12))\n",
    "\n",
    "# 总数 & 爆款数\n",
    "total_videos = len(df)\n",
    "viral_videos = (df['actual_views'] > viral_threshold).sum()\n",
    "\n",
    "# 占比\n",
    "viral_ratio = viral_videos / total_videos\n",
    "\n",
    "print(f\"总视频数：{total_videos}\")\n",
    "print(f\"爆款（>{viral_threshold:,} views）数量：{viral_videos}\")\n",
    "print(f\"占比：{viral_ratio:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea : new loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penalize underestimation of popular videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(10, 18, 200)\n",
    "center = (13.5 + 16.5) / 2\n",
    "sharpness = 6 / (16.5 - 13.5)\n",
    "w = 1 + 2 * torch.sigmoid((x - center) * sharpness)\n",
    "plt.plot(x.numpy(), w.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
