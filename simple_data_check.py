import torch
import pandas as pd
from torch.utils.data import random_split
from data.dataset import Dataset

def simple_data_check():
    """ç®€å•æ£€æŸ¥æ•°æ®é›†åˆ’åˆ†"""
    
    print("=== æ•°æ®é›†åˆ’åˆ†æ£€æŸ¥ ===")
    
    # åˆ›å»ºæ•°æ®é›†ï¼ˆä¸ä½¿ç”¨å˜æ¢ï¼‰
    dataset = Dataset(
        dataset_path="dataset",
        split="train_val",
        metadata=["title"],
        transforms=None
    )
    
    print(f"æ€»æ•°æ®é›†å¤§å°: {len(dataset)}")
    
    # ä½¿ç”¨ç›¸åŒçš„å‚æ•°è¿›è¡Œåˆ’åˆ†
    val_split = 0.1
    seed = 42
    
    total_size = len(dataset)
    val_size = int(total_size * val_split)
    train_size = total_size - val_size
    
    print(f"è®­ç»ƒé›†å¤§å°: {train_size}")
    print(f"éªŒè¯é›†å¤§å°: {val_size}")
    print(f"éªŒè¯é›†æ¯”ä¾‹: {val_split}")
    print(f"éšæœºç§å­: {seed}")
    
    # åˆ’åˆ†æ•°æ®é›†
    train_dataset, val_dataset = random_split(
        dataset, 
        [train_size, val_size],
        generator=torch.Generator().manual_seed(seed)
    )
    
    # è·å–ç´¢å¼•
    train_indices = set(train_dataset.indices)
    val_indices = set(val_dataset.indices)
    
    print(f"\nå®é™…è®­ç»ƒé›†ç´¢å¼•æ•°é‡: {len(train_indices)}")
    print(f"å®é™…éªŒè¯é›†ç´¢å¼•æ•°é‡: {len(val_indices)}")
    
    # æ£€æŸ¥é‡å 
    overlap = train_indices.intersection(val_indices)
    print(f"é‡å çš„ç´¢å¼•æ•°é‡: {len(overlap)}")
    
    if len(overlap) > 0:
        print("âŒ å‘ç°æ•°æ®æ³„éœ²ï¼è®­ç»ƒé›†å’ŒéªŒè¯é›†æœ‰é‡å ")
        return False
    else:
        print("âœ… æ²¡æœ‰æ•°æ®æ³„éœ²ï¼Œè®­ç»ƒé›†å’ŒéªŒè¯é›†å®Œå…¨åˆ†ç¦»")
    
    # æ£€æŸ¥è¦†ç›–
    all_indices = train_indices.union(val_indices)
    expected_indices = set(range(len(dataset)))
    
    if all_indices == expected_indices:
        print("âœ… ç´¢å¼•è¦†ç›–å®Œæ•´")
    else:
        print("âŒ ç´¢å¼•è¦†ç›–ä¸å®Œæ•´")
        return False
    
    # æ£€æŸ¥ä¸€äº›å®é™…çš„ID
    print("\næ£€æŸ¥å®é™…ID...")
    
    # è·å–ä¸€äº›è®­ç»ƒé›†ID
    train_ids = []
    for i, idx in enumerate(list(train_indices)[:10]):
        item = dataset[idx]
        train_ids.append(item['id'])
    
    # è·å–ä¸€äº›éªŒè¯é›†ID
    val_ids = []
    for i, idx in enumerate(list(val_indices)[:10]):
        item = dataset[idx]
        val_ids.append(item['id'])
    
    print(f"è®­ç»ƒé›†å‰10ä¸ªID: {train_ids}")
    print(f"éªŒè¯é›†å‰10ä¸ªID: {val_ids}")
    
    # æ£€æŸ¥IDé‡å 
    train_id_set = set(train_ids)
    val_id_set = set(val_ids)
    id_overlap = train_id_set.intersection(val_id_set)
    
    if len(id_overlap) > 0:
        print(f"âŒ å‘ç°IDé‡å : {id_overlap}")
        return False
    else:
        print("âœ… å‰10ä¸ªIDæ²¡æœ‰é‡å ")
    
    # è¯»å–åŸå§‹æ•°æ®ç»Ÿè®¡
    print("\n=== åŸå§‹æ•°æ®ç»Ÿè®¡ ===")
    train_val_csv = pd.read_csv("dataset/train_val.csv")
    test_csv = pd.read_csv("dataset/test.csv")
    
    print(f"train_val.csv å¤§å°: {len(train_val_csv)}")
    print(f"test.csv å¤§å°: {len(test_csv)}")
    
    # æ£€æŸ¥viewsåˆ†å¸ƒ
    views = train_val_csv['views'].values
    print(f"\nViewsåˆ†å¸ƒ:")
    print(f"  æœ€å°å€¼: {views.min():,}")
    print(f"  æœ€å¤§å€¼: {views.max():,}")
    print(f"  å‡å€¼: {views.mean():,.2f}")
    print(f"  ä¸­ä½æ•°: {pd.Series(views).median():,.2f}")
    print(f"  æ ‡å‡†å·®: {views.std():,.2f}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤ID
    train_val_ids = set(train_val_csv['id'].values)
    test_ids = set(test_csv['id'].values)
    
    print(f"\ntrain_val å”¯ä¸€IDæ•°é‡: {len(train_val_ids)}")
    print(f"test å”¯ä¸€IDæ•°é‡: {len(test_ids)}")
    
    # æ£€æŸ¥train_valå’Œtestä¹‹é—´æ˜¯å¦æœ‰é‡å 
    train_test_overlap = train_val_ids.intersection(test_ids)
    if len(train_test_overlap) > 0:
        print(f"âŒ train_valå’Œtestä¹‹é—´æœ‰IDé‡å : {len(train_test_overlap)}ä¸ª")
        print(f"é‡å IDç¤ºä¾‹: {list(train_test_overlap)[:5]}")
        return False
    else:
        print("âœ… train_valå’Œtestä¹‹é—´æ²¡æœ‰IDé‡å ")
    
    return True

if __name__ == "__main__":
    success = simple_data_check()
    if success:
        print("\nğŸ‰ æ•°æ®é›†åˆ’åˆ†æ£€æŸ¥é€šè¿‡ï¼")
    else:
        print("\nâš ï¸  æ•°æ®é›†åˆ’åˆ†å­˜åœ¨é—®é¢˜ï¼") 